{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jkchandalia/nlp/blob/main/NLP_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB2JOABMiM4Q"
      },
      "source": [
        "# **Intro to Practical Hands-on Deep Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zJKw3PM8-vL"
      },
      "source": [
        "**Import** Libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9vmG-hk894X"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rht5jZf89DGB"
      },
      "source": [
        "# Structuring Unstructured Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's easy to compare numbers and vectors."
      ],
      "metadata": {
        "id": "qsTjkHTZRNbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def array_isclose(arr1, arr2):\n",
        "  for i in range(len(arr1)):\n",
        "    if not(math.isclose(arr1[i], arr2[i], rel_tol = 0.1)):\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "arr1 = [2.3, 1.01, 4.5]\n",
        "arr2 = [2.2, 1.00, 4.3]\n",
        "arr3 = [1.8, 1.5, 4.5]\n",
        "\n",
        "print(\"Is arr1 close to arr2: \", array_isclose(arr1, arr2))\n",
        "print(\"Is arr2 close to arr3: \", array_isclose(arr2, arr3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guMFeLT8Orhq",
        "outputId": "381677fd-507e-4273-cf2b-4135766a55a1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is arr1 close to arr2:  True\n",
            "Is arr2 close to arr3:  False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about images? Or sentences? We will start by looking at two sentences that are similar:\n",
        "\n",
        "\n",
        "\n",
        "### 1.   **The cat took a nap on the rug.**\n",
        "<figure>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1KCjrHAU1V7P73OFjzNiabIR0nfKfpen7' alt=\"History of LLMs\", width=\"200\" height=\"200\"/>\n",
        "<figcaption>By DALL-E: Cat taking nap on rug</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "### 2.   **The feline slept in the sunshine.**\n",
        "<figure>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1gtHWnVm-fPSruzxjMS1GHK0bgLqYBYyo' alt=\"History of LLMs\", width=\"200\" height=\"200\"/>\n",
        "<figcaption>By DALL-E: Feline sleeping in sunshine</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "\n",
        "Do we feel like there’s a similar idea being presented in these two sentences? \n",
        "What about the below sentence?\n",
        "\n",
        "\n",
        "### 3.   **The cat took a bite of the rug.**\n",
        "\n",
        "<figure>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1DtnL-sFkhmFKnOAXPJ4q5n9z-eoZMIP0' alt=\"History of LLMs\", width=\"200\" height=\"200\"/>\n",
        "<figcaption>By DALL-E: Cat biting rug</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "54nPj9oICG1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bag of Words"
      ],
      "metadata": {
        "id": "s2xgdoyssU9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TF-IDF"
      ],
      "metadata": {
        "id": "F6Y7WPH9saoq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uOqvJg8AsUT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is there a way to quantify our feelings about the differences/similarities between these three sentences? Let's try something simple and represent each sentence as an array:"
      ],
      "metadata": {
        "id": "bfFtyiBJCtGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = ['The', 'cat', 'took', 'a', 'nap', 'on', 'the', 'rug']\n",
        "s2 = ['The', 'feline', 'slept', 'in', 'the', 'sunshine']\n",
        "s3 = ['The', 'cat', 'took', 'a', 'bite', 'of', 'the', 'rug']\n"
      ],
      "metadata": {
        "id": "YvNGp-m_Cz0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let’s try to quantify the differences between the vectors by representing a word match as a 1 and a word mismatch as a 0. For instance, for the first two sentences we have:\n",
        "\n",
        "[1, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "Because only ‘The’ is common between the sentences. \n",
        "\n",
        "For the first and third sentences, we have:\n",
        "\n",
        "[1, 1, 1, 1, 0, 0, 1, 1]\n"
      ],
      "metadata": {
        "id": "MBsbLw8XEPS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because ‘The’, ‘cat’, ‘took’, ‘a’, ‘the’, and ‘rug’ are common words in the two sentences. If we simple add up all the numbers in each vector to get an idea of how similar the sentences are, we have:\n",
        "\n",
        "1 for similarity between sentences 1 and 2\n",
        "6 for similarity between sentences 1 and 3\n",
        "\n",
        "Using our approach, which sentences are more similar? Does this match our intuition for which sentences are most similar/dissimilar out of our examples? How are we handling sentences of different length?\n"
      ],
      "metadata": {
        "id": "0I7Uow_XEawV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To quantify differences between sentences, we need to represent them in a numerical way. However, we also need this numerical representation to reflect what the sentences actually mean, i.e., capture the semantic content of these sentences and words. How can we do that?\n"
      ],
      "metadata": {
        "id": "bJE8zONoEhOM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Large Language Models (LLM)"
      ],
      "metadata": {
        "id": "dGUHKiJpEqyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1x0w2nrDUcuAUOqwbjpM8NKrH2T3m5gLH' alt=\"History of LLMs\", width=\"900\" height=\"600\"/>\n",
        "<figcaption>Image Caption</figcaption></center>\n",
        "</figure>"
      ],
      "metadata": {
        "id": "KN8bYZtfHBo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Encoder\n",
        "\n",
        "To train a model like BERT that has 100M parameters, we need a lot of data. As some of you in the field may know, data is the fuel that powers our models and it can be hard to acquire and expensive to label. BERT is trained in a self-supervised way using masked language modeling and next sentence prediction. "
      ],
      "metadata": {
        "id": "Hey5iWMwF5LA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self-supervised learning"
      ],
      "metadata": {
        "id": "qFFkvoLQKXcU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Masked Language Modelling (MLM)*\n",
        "\n",
        "Let’s look at the following sentence and try to predict what word should be in the sentence instead of the **< MASK >** placeholder. \n",
        "\n",
        "The clever **< MASK >** got the cheese without springing the trap. \n",
        "\n",
        "What do we think the word is? By training BERT to predict the correct word, but over hundreds of millions of sentences, we teach the model to learn relationships between words and become a better language model. \n"
      ],
      "metadata": {
        "id": "cq75XULbDOog"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AUXqyASPDvhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Next Sentence Prediction (NSP)*"
      ],
      "metadata": {
        "id": "hP2eFWq9D_Nh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The other way BERT was trained was by taking two pairs of sentences and predicting if the two sentences are related, i.e., does sentence 2 follow logically after sentence 1. As an example, let’s take this first sentence:\n",
        "\n",
        "**The cat climbed up a tree and got stuck.**\n",
        "\n",
        "Now, let’s look at two possible next sentences: \n",
        "\n",
        "**1. Letters can be posted in person during business hours.**\n",
        "\n",
        "**2. The firefighter came with a ladder and climbed up to rescue the cat**\n",
        "\n",
        "Which one makes more sense? By also training BERT over the next sentence prediction, we also capture more semantic content in this model. \n"
      ],
      "metadata": {
        "id": "x5_ZmM4iwLeh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention Mechanism"
      ],
      "metadata": {
        "id": "8ba7VbG5GSoW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traditionally, modeling sequences has been challenging but the general idea is that we want to express the information contained in the sequence into a compressed form and use that compressed form to generate an output. The output could be a translation of the original sequence into a new language or a classification. Taking the example from above, this means the above sentences that are semantically similar will be mapped to something similar in the compressed form while dissimilar sentences will be further apart. What transformed (pun intended) this compression step is the concept of attention. \n",
        "\n",
        "I’m going to need to gloss over the technical details, but basically for each item in our sequence, we ask or query each item in our sequence to see how important or relevant it is for us. Of course this is done through matrix multiplications which we will not get into here. For this example sentence:\n",
        "\n",
        "“The cat purred in happiness”\n",
        "\n",
        "one could imagine that cat and purr attend to each other, likely because the english language reflects that cats purring is much more likely than say an elephant purring. After going through an attention layer, each item in the transformed sequence is actually a mixture of itself and all other items that contribute to the meaning of itself. By passing inputs through many such layers, we generate a representation of our original input that does capture the semantic meaning of our original input. \n"
      ],
      "metadata": {
        "id": "W0WOhKR4KHGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Learning"
      ],
      "metadata": {
        "id": "_rSXb_KXGZOA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Generation:\n",
        "Use chatgpt to create a poem that we will classify in the next section!"
      ],
      "metadata": {
        "id": "6aoDedveG5gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://chat.openai.com/"
      ],
      "metadata": {
        "id": "Obx0QjBgByIP"
      }
    }
  ]
}